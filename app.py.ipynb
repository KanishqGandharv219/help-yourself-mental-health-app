{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14bff174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I'm feeling down today. Can I afford to sleep alone, or can I just go out and do my homework all alone? [SEP] What you might want to know is that you may need to consider starting therapy and considering working with others who would benefit from you. If you feel comfortable working with others who feel in their best interest, or a combination of both. I'm not sure how well you are doing, but maybe if it's been a long, busy weekend or if it's an all-consuming weekend, consider discussing your goals and finding what works best for you. What you find is you can work with others\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Convert the Windows path to a POSIX-style path\n",
    "model_path = Path(r\"C:\\Users\\kanis\\OneDrive\\Desktop\\Major Project\\final\\fine_tuned\").resolve().as_posix()\n",
    "\n",
    "# Load the slow tokenizer (use_fast=False) from the local directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, local_files_only=True, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True, trust_remote_code=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def generate_response(prompt, max_length=128, do_sample=True):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_length=max_length, do_sample=do_sample)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"I'm feeling down today\"\n",
    "print(\"Response:\", generate_response(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e356b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc6cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
